# 사용자 시나리오: 고급 트레이딩 데이터 분석 파이프라인

## 1. 개요 (Overview)
본 문서는 **하이브리드 트레이딩 분석 시스템**에 대한 사용자 시나리오를 정의합니다. 이는 **퀀트 운영자(Quantitative Operator)**가 시장 데이터와 시스템 로그를 업로드하여 다차원적인 통찰력을 얻는 전체 워크플로우를 상세히 설명합니다.

**목표**: 수치적인 시장 데이터와 비정형 시스템 로그를 결합하여 트레이딩 성과와 시스템 건전성을 종합적으로 분석하는 것입니다.

## 2. 행위자 및 전제 조건 (Actors & Pre-conditions)
*   **행위자**: 퀀트 운영자 / 시스템 관리자
*   **전제 조건**:
    *   사용자가 트레이딩 엔진에서 거래 데이터(`.pkl`)와 시스템 로그(`.log`, `.log.gz`)를 수집했습니다.
    *   데이터가 서버의 `data/` 디렉토리에 안전하게 업로드되었습니다.

## 3. 상세 워크플로우 단계 (Detailed Workflow Steps)

### 1단계: 데이터 로딩 및 수집 (Data Loading & Ingestion)
*   **사용자 동작**: 지정된 디렉토리에 파일을 업로드합니다.
*   **시스템 동작**:
    1.  디렉토리를 스캔하여 지원되는 형식을 확인합니다.
    2.  **트랜잭션 데이터** 식별: `preprocessed_trading_data_stage4_YYYYMMDD.pkl`.
        - **내용**: 가격, 거래량 및 **16개의 시그널 컬럼**(`Signal_indicator_indicator`, `Signal_limit_indicator_...` 등)을 포함한 시계열 데이터.
    3.  **시스템 로그** 식별 (`.log`), 압축파일(`.gz`) 자동 처리.
    4.  데이터 무결성 검증 (메타파일 확인, 압축 해제).

### 2단계: 데이터 전처리 (Data Preprocessing)
*   **목표**: 이기종 분석 엔진을 위한 원시 데이터 준비.
*   **절차**:
    *   **시간 동기화**: 로그 타임스탬프와 거래 실행 타임스탬프를 정렬합니다.
    *   **수치 정제** (Pandas): 누락된 가격/거래량 데이터 처리(전방 채우기), 수치 스케일 정규화.
    *   **텍스트 구조화**: 비정형 로그 라인을 구조화된 이벤트로 파싱합니다.
        *   **대상 패턴**:
            *   **코어 시스템**: `[INFO] core.logging - ...`
            *   **시그널 엔진 (AEP)**: `[WARNING] core.logging - [AEP] ...`
            *   **적응형 엔진 (ADPT)**: `[WARNING] core.logging - [ADPT] ...`
        *   **추출 필드**: `타임스탬프`, `모듈`(AEP/ADPT), `시그널명`, `값`.

### 3단계: 다면 분석 실행 (Multi-Faceted Analysis Execution)
시스템은 세 가지 분석 스트림을 동시에 수행합니다:

#### A. 기술적 분석 (Pandas)
*   **목표**: 시장 실행 성과 평가.
*   **지표**:
    *   심볼/거래별 **손익(PnL)** 분석.
    *   **기술적 지표**: SMA(이동평균), RSI, 변동성 지표 계산.
    *   **시그널 일관성 검사**:
        *   특정 로그 이벤트(예: `[AEP] ✅ 최근 신호 발견 (Signal_X): 2025-12-26... (값: 1)`)를 해당 타임스탬프/데이터프레임 컬럼과 비교.
        *   데이터프레임의 해당 타임스탬프에 동일한 시그널 값(`1` 또는 `-1`)이 존재하는지 검증.

#### B. 진단 및 처방적 분석 (LangGraph + Ontology)
*   **목표**: 시스템 이상 징후 식별 및 수정 권고.
*   **기술**: **LangGraph** (워크플로우) + **도메인 온톨로지** (지식 베이스).
*   **절차**:
    1.  **수집 노드**: 파싱된 에러 로그를 스트리밍.
    2.  **매핑 노드**: 로그 이벤트를 **시스템 지식 그래프**에 매칭 (예: "Timeout"을 "Gateway Module"과 연결).
    3.  **근본 원인 분석 노드**: LLM 기반 추론을 사용하여 그래프를 순회하고 실패 원인을 파악.
    4.  **처방 노드**: 사람이 읽을 수 있는 "해결책" 생성 (예: "VM-3 재시작", "연결 타임아웃 증가").

#### C. 예측 분석 (PyTorch)
*   **목표**: 향후 전략 파라미터 최적화를 위한 단기 시장 추세 예측.
*   **기술**: **PyTorch** (딥러닝).
*   **절차**:
    1.  **데이터셋 구축**: `가격` + `거래량` + `기술적 지표`로 구성된 윈도우.
    2.  **모델 추론**: 사전 학습된 **LSTM/Transformer** 모델에 데이터 입력.
    3.  **출력**: 예측된 가격 변동(상승/하락/보합) 또는 변동성 구간 의도.

### 4단계: 결과 및 보고 (Outcome & Reporting)
*   **시스템 동작**: 모든 통찰력을 통합 보고서로 집계.
*   **사용자 결과물**:
    *   **성과 대시보드**: PnL 및 기술적 지표 차트.
    *   **건전성 보고서**: 진단된 사건 목록 및 처방된 조치.
    *   **전략 조언**: 예측된 변동성에 기반한 전략 파라미터 조정 제안.

## 4. 시나리오 요약 테이블 (Scenario Summary Table)

| 단계 | 입력 데이터 | 기술 스택 | 주요 출력 |
| :--- | :--- | :--- | :--- |
| **수집 (Ingestion)** | `.log`, `.pkl` | Python (IO, Gzip) | 검증된 파일 스트림 |
| **전처리 (Preprocessing)** | Raw Streams | Pandas, Regex | 정제된 데이터프레임, 구조화된 로그 |
| **기술적 분석 (Tech Analysis)** | Trade Data | **Pandas** | SMA, 변동성, PnL 지표 |
| **진단 (Diagnostic)** | System Logs | **LangGraph**, **Ontology** | 근본 원인, 복구 계획 |
| **예측 (Predictive)** | Market Data | **PyTorch** | 가격/변동성 예측 |
